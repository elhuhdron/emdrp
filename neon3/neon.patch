diff --git a/neon/layers/layer.py b/neon/layers/layer.py
index 247b41a..06360da 100644
--- a/neon/layers/layer.py
+++ b/neon/layers/layer.py
@@ -831,13 +831,14 @@ class Convolution(ParameterLayer):
         pad_tuple = tuple(self.convparams[k] for k in ['pad_' + d for d in padstr_dim])
         str_tuple = tuple(self.convparams[k] for k in ['str_' + d for d in padstr_dim])
         dil_tuple = tuple(self.convparams[k] for k in ['dil_' + d for d in padstr_dim])
+        shp_tuple = tuple(self.fshape[:input_spatial_dim])
 
         fmt_tuple = (self.name,) + self.in_shape + self.out_shape + (
-                     pad_tuple + str_tuple + dil_tuple)
+                     pad_tuple + str_tuple + dil_tuple + shp_tuple)
         fmt_string = "Convolution Layer '%s': " + \
                      input_spatial_str + " inputs, " + output_spatial_str + " outputs, " + \
                      padstr_str + " padding, " + padstr_str + " stride, " + \
-                     padstr_str + " dilation"
+                     padstr_str + " dilation, " + padstr_str + " shape"
 
         return ((fmt_string % fmt_tuple))
 
diff --git a/neon/models/model.py b/neon/models/model.py
index 04eb7e1..c61fc4c 100644
--- a/neon/models/model.py
+++ b/neon/models/model.py
@@ -388,6 +388,10 @@ class Model(NervanaObject):
 
         pdict['model'] = self.layers.get_description(get_weights=get_weights,
                                                      keep_states=keep_states)
+        
+        # xxx - watkinspv, hack to save some data meta
+        if hasattr(self, 'batch_meta'): pdict['batch_meta'] = self.batch_meta
+        
         return pdict
 
     def save_params(self, param_path, keep_states=True):
@@ -485,6 +489,9 @@ class Model(NervanaObject):
                 # could come about when switching backend types (ex GPU to CPU)
                 logger.warning("Problems restoring existing RNG state: %s", str(e))
 
+        # xxx - watkinspv, hack to load some data meta
+        if 'batch_meta' in model_dict: self.batch_meta = model_dict['batch_meta']
+
     # serialize tells how to write out the parameters we've learned so
     # far and associate them with layers. it can ignore layers with no
     # learned parameters. the model stores states to pass to the
