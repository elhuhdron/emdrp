[data]
type=data
dataIdx=0

[labels]
type=data
dataIdx=1

# layer 1 - for input image of size NxN produce NxN feature maps
[conv1]
type=conv
inputs=data
channels=1
filters=96
padding=3
stride=1
filterSize=7
neuron=relu
initW=0.0001
sumWidth=8
sharedBiases=1
gpu=0

# response normalization across feature maps
[rnorm1]
type=cmrnorm
inputs=conv1
channels=96
size=31

# overlapping pooling to produce N/2xN/2 feature maps
[pool1]
type=pool
pool=max
inputs=rnorm1
start=0
sizeX=3
stride=2
outputsX=0
channels=96

# layer 2 -produce N/2xN/2 feature maps
[conv2]
type=conv
inputs=pool1
filters=256
padding=2
stride=1
filterSize=5
channels=96
neuron=relu
initW=0.01
sumWidth=8
sharedBiases=1

# response normalization across feature maps
[rnorm2]
type=cmrnorm
inputs=conv2
channels=256
size=31

# overlapping pooling to produce N/4xN/4 feature maps
[pool2]
type=pool
pool=max
inputs=rnorm2
start=0
sizeX=3
stride=2
outputsX=0
channels=256

# layer 3 - convolution only to produce N/4 x N/4 feature maps
[conv3]
type=conv
inputs=pool2
filters=384
padding=1
stride=1
filterSize=3
channels=256
neuron=relu
initW=0.01
sumWidth=4
sharedBiases=1

# layer 4 - convolution only to produce N/4 x N/4 feature maps
[conv4]
type=conv
inputs=conv3
filters=384
padding=1
stride=1
filterSize=3
channels=384
neuron=relu
initW=0.01
sumWidth=4
sharedBiases=1

# layer 5 - convolution and max pool to produce N/8 x N/8 feature maps
[conv5]
type=conv
inputs=conv4
filters=256
padding=1
stride=1
filterSize=3
channels=384
neuron=relu
initW=0.01
sumWidth=4
sharedBiases=1

[pool5]
type=pool
pool=max
inputs=conv5
start=0
sizeX=3
stride=2
outputsX=0
channels=256

[fc1]
type=fc
outputs=4096
inputs=pool5
initW=0.01
#neuron=logistic
neuron=ident

[dropout1]
type=dropout
inputs=fc1

[fc2]
type=fc
outputs=4096
inputs=dropout1
initW=0.01
#neuron=logistic
neuron=ident

[dropout2]
type=dropout
inputs=fc2

[fc3]
type=fc
outputs=768
inputs=dropout2
initW=0.01
#neuron=logistic
neuron=ident

[logprob]
type=cost.ice
inputs=labels,fc3
gpu=0

