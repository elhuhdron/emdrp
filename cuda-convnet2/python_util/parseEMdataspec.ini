
# parseEMdataspec.ini
# ini specification file for EMDataParser which generates data batches for cuda-convnet2
# Based on arguments to previous script datapkgEMnew.py that generated data for cuda-convnet-EM-alpha EMGPUInd provider
# File is meant to be read with configobj python module.
# http://www.voidspace.org.uk/python/articles/configobj.shtml
# 
# NOTE: as of version 5.0.6 inline comments do NOT work for specification lines
#   and types need at least ONE argument to not throw a validation error (for required vals, just specify min/max)

# Original examples from help for configobj
# name = string(min=1, max=30, default=Fred)
# age = float(min=0, max=200, default=29)
# attributes = string_list(min=5, max=5, default=list('arms', 'legs', 'head', 'body', 'others'))
# likes_cheese = boolean(default=True)
# favourite_color = option('red', 'green', 'blue', default="red")

##############################
# Required options
##############################

# Input image EM data (hdf5)
imagesrc            = string(min=1)       

# Input segmented labels (hdf5)
labelsrc            = string(min=1)                 

# Path to write hdf5 inputs and outputs
outpath             = string(min=1)

# XYZ zero-based coordinates to corner chunk to use for random batches (ignored in chunkrange mode, see below)
chunk_rand          = int_list(min=3, max=3)    

# XYZ zero-based coordinates to corner chunk to use for tiled batches (ignored in chunkrange mode, see below)
chunk_tiled         = int_list(min=3, max=3)    

##############################
# Optional options
##############################

# Debugging output
verbose             = boolean(default=False)        

# Variable name of the dataset (EM hdf5 file)
dataset             = string(default='data')        

# Variable name of user's labels (labels hdf5 file)
username            = string(default='labels')      

# Product is num_cases_per_batch, tile_size*image_out_size must be factor of size_rand
tile_size           = int_list(min=3, max=3, default=list(64,64,1))

# Size (xy) of the image examples to be presented to convnet
image_size          = integer(min = 3, default=65)

# Number of zslices in examples to be presented to convnet (each case), must be 1 or 3
nzslices            = integer(min=1, max=3, default=1)

# Augmentations mask to use for randomized examples (== 3 for xy reflections only)
augs_mask           = integer(min=0, max=15, default=7)

# Label priors to use for randomized examples (default uniform)
label_priors        = float_list(default=list(-1.0))    

# How labels are selected / balanced for network presentation
# Also defines the actual labels when independent_labels is False
select_label_type   = option('ICS_OUT','ICS_ECS_MEM','ICS_OUT_BRD','ICS_ECS_MEM_BRD', default='ICS_OUT')

# How input labels are to be interpreted by the network when independent_labels is True
label_type          = option('ICSorOUT','ICSorECSorMEM','ICSorECS','ICSorMEM','affin2','affin4','affin6', default='ICSorOUT')

# specify ECS label, -1 is last label, -2 is default (use constant defined in parseEMdata)
ECS_label           = integer(min=-2, default=-2)

# specify the data type for the labels (numpy unsigned integer types as string)
cubeLblTypeStr      = option('uint16','uint32','uint64', default='uint16')

# The order of the xyz dimensions as a string, the last dim becomes the new z dim
dim_ordering        = option('xyz','xzy','zyx', default='xyz')

# Size (xy) of the number of output pixels, tile_size*image_out_size must be factor of size_rand
# for autoencoders indicates size of image any data-processing steps in convnet
image_out_size      = integer(min=1, default=1)       

# Maximum size (xy) of the randomized offset to use when selecting random images based on label lookup table.
# offset larger than image_out_size can help remove correlations between the output pixels.
# offset of 1 indicates that selection is always based on the center pixel only.
image_out_offset    = integer(min=1, default=1)       

# Specify that hdf5 input files are stored in C-order
hdf5_Corder         = boolean(default=False)        

# Specify that chunk indices are centered on origin (0,0,0)
origin_chunk_inds   = boolean(default=False)    

# Whether to generate winner-take all (softmax) or independent label types
# independent labels are required for multiple pixel outputs
independent_labels  = boolean(default=True) 

# Do not generate label lookup for generation of random batches (for test / features only, saves some time on init)
no_label_lookup     = boolean(default=False) 

# Do not generate or return labels at all, intended for autoencoders or large feature dumps over mostly unlabeled areas
no_labels           = boolean(default=False) 

# Return all zeros labels to convnet (for large feature dumps where convnet still expecting labels)
zero_labels         = boolean(default=False) 

# Adjust exported probabilities (probability feature writing mode) with this prior.
# Length must be same as either number of outputs (not independent_labels) 
#   or number of independent types (independent_labels)
# For independent outputs applied to each output independently (reweights "true" target).
# Any 0 indicates no bayesian reweighting, must be at least two outputs from convnet.
# Specifying an extra prior for independent outputs uses a third class that is 1-(sum probs)
prior_test          = float_list(min=2, default=list(0.0, 0.0))

# if prior reweighting is enabled and there are independent labels, then setting this does the reweighting
#   completely independently per output. if false, then reweighting is done independently per pixel output but
#   across the pixel types (the independent label types).
prior_test_indep    = boolean(default=False) 

##############################
# Optional options for "chunklist" or "chunkrange" modes versus regular mode (rand / tiled)
##############################

# Offset in chunk_rand to use for random batches
offset_rand         = int_list(min=3, max=3, default=list(0,0,0))       

# Offset in chunk_tiled to use for appending tiled batches
offset_tiled        = int_list(min=3, max=3, default=list(0,0,0))           

# Set these to use "chunklist" or "chunkrange" mode which loads cubes on-the-fly from different parts of the dataset.
# format is X1,Y1,Z1, X2,Y2,Z2, ...
chunk_range_beg     = int_list(min=0, default=list())    

# chunk_range_beg is set and end range is empty, then chunk_range_beg are assumed to be single chunks (chunklist mode)
# otherwise these are the ending chunks for the ranges and must be same length as chunk_range_beg (chunkrange mode)
# the range is open on the end, i.e., the chunk at chunk_range_end is NOT included
# format is X1,Y1,Z1, X2,Y2,Z2, ...
chunk_range_end     = int_list(min=0, default=list())    

# define offsets for "chunklist" mode, if this list is empty, defaults to all zeros
# otherwise must be same length as chunk_range_beg/end (offsets per range for chunkrange or per chunk for chunklist)
# format is X1,Y1,Z1, X2,Y2,Z2, ...
offset_list         = int_list(min=0, default=list())    

# if chunklist or chunkrange mode, how many starting at beginning of chunk_range_beg to use for rand batches
# use -1 to indicate to use all available batches in the list or in all ranges as random batches
chunk_range_rand    = integer(min=-1, default=1)

# if chunklist or chunkrange mode, whether to select chunks in order or randomly for randomized batches
chunk_list_rand     = boolean(default=False)

##############################
# Optional options that get re-ordered on reslice
##############################

# Size of voxels to sample over for random batches
size_rand           = int_list(min=3, max=3, default=list(256,256,128)) 

# Number of zslices to append for tiled batches. Default to Z value of rand_size (after reslice re-ordered)
# Use nz_tiled = 0 to not load any tiled batches. nz_tiled should be 0 for feature dumps and for chunklist mode
nz_tiled            = integer(min=-1, default=-1)

# Frontend "read_size" area for a single set of dense labels. Default to rand_size
read_size           = int_list(min=3, max=3, default=list(-1,-1,-1))

# Use along with read_size to specify border around read_size cubes not to select rand examples from
read_border         = int_list(min=3, max=3, default=list(1,1,1))

##############################
# Optional data pre-processing options
##############################

# Scalar mean value to subtract from image examples (< 0 for mean over all input data, 0 to do nothing)
EM_mean             = float(min=-1.0, max=256.0, default=-1.0)

# Scalar std value to divide out of image examples (< 0 for std over all input data, 1 to do nothing)
EM_std              = float(min=-1.0, max=256.0, default=1.0)

# For pre-processing that requires initialization, how many random batches to use for init
preproc_nbatches    = integer(min=1, default=5)

# Subtract overall mean and divide variance from all batches, uses init
overall_normalize   = boolean(default=False)

# Subtract per-pixel mean and divide variance from all batches, uses init
pixel_normalize     = boolean(default=False)

# Subtract per-case mean and divide variance from all batches
case_normalize      = boolean(default=False)

# whiten the input data using specified method, uses init, not used if loading whitening matrix (unless None)
whiten              = option('none','zca','pca','czca','cpca', default='none')

# regularization parameter to use for whitening, not used if loading whitening matrix
whiten_epsilon      = float(min=1e-7, default=1e-5)

# Load a previously calculated whitening matrix
whiten_load         = string(default='')

# Typical preprocessing of images, upsample, apply filter, downsample, apply optional gamma
em_standard_filter  = int_list(min=2, max=2, default=list(0,0))
em_standard_idelta  = float_list(min=2, max=2, default=list(0.5,0.5))
em_standard_gamma   = float(min=1e-5, max=10, default=1.0)

