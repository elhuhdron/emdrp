
# File is meant to be read with configobj python module.
# http://www.voidspace.org.uk/python/articles/configobj.shtml
# 
# See python_util/parseEMdataspec.ini for types / defaults / valid options
# NOTE: inline comments are OK in this file (but not in specification file)
# 
# Created on Jul 20, 2015, pwatkins

##############################
# Variables
#   Do not define any names that conflict with option names.
##############################
datadir         = ../data

##############################
# Required options
##############################

# Input image EM data (hdf5)
imagesrc            = %(datadir)s/M0007_33_raw_data.h5

# Input segmented labels (hdf5)
labelsrc            = %(datadir)s/M0007_33_gt_labels.h5

# Path to write hdf5 inputs and outputs
outpath             = %(datadir)s

# XYZ zero-based coordinates to corner chunk to use for random batches
chunk_rand          = 0,0,0

# XYZ zero-based coordinates to corner chunk to use for tiled batches
chunk_tiled         = 0,0,0    

##############################
# Optional options
##############################

# Debugging output
verbose             = False        

# Variable name of the dataset (EM hdf5 file)
dataset             = data_mag1 

# Variable name of user's labels (labels hdf5 file)
username            = labels

# Product is num_cases_per_batch (*tile_size must be factor of size_rand)
tile_size           = 8,8,64   # 128x128x128 cube size 16 out

# Size (xy) of the image examples to be presented to convnet (xxx - odd if not affin2?)
image_size          = 64

# Number of zslices in examples to be presented to convnet (each case), must be 1 or 3
nzslices            = 1

# Augmentations mask to use for randomized examples (== 3 for xy reflections only)
augs_mask           = 7

# Label priors to use for randomized examples (default uniform), MEM, ICS, ECS
label_priors        = 0.3333334,0.3333333,0.3333333

# How labels are selected / balanced for network presentation
select_label_type  = ICS_ECS_MEM

# How input labels are to be interpreted by the network
label_type          = ICSorECSorMEM

# specify ECS label explicitly
ECS_label           = 1

# specify the data type for the labels (numpy unsigned integer types as string)
cubeLblTypeStr      = uint16

# The order of the xyz dimensions as a string, the last dim becomes the new z dim
dim_ordering        = 'xyz'

# Size (xy) of the number of output pixels, *image_out_size must be a factor of size_rand
image_out_size      = 16

# Specify that hdf5 input files are stored in C-order
hdf5_Corder         = False        

# Specify that chunk indices are centered on origin (0,0,0)
origin_chunk_inds   = False    

# Whether to generate winner-take all (softmax) or independent label types
# independent labels are required for multiple pixel outputs
independent_labels  = True 

# Do not generate label lookup for generation of random batches (for test / features only, saves some time on init)
no_label_lookup     = False

# Do not generate labels at all (used for autoencoders)
no_labels           = False

# Adjust exported probabilities (probability feature writing mode) with this prior.
# Length must be same as either number of outputs (not independent_labels) 
#   or number of independent types (independent_labels)
# For independent outputs applied to each output independently (reweights "true" target).
# Any 0 indicates no bayesian reweighting, must be at least two outputs from convnet
# order for 3class ICSorECSorMEM independent_labels is ICS,ECS,MEM
prior_test          = 0.63666153,0.11633038,0.24700809

# if prior reweighting is enabled and there are independent labels, then setting this does the reweighting
#   completely independently per output. if false, then reweighting is done independently per pixel output but
#   across the pixel types (the independent label types). 
#prior_test_indep    = False

##############################
# Optional options for "chunklist" or "chunkrange" modes versus regular mode (rand / tiled)
##############################

# Offset in chunk_rand to use for random batches
offset_rand         = 0,0,0       

# Offset in chunk_tiled to use for appending tiled batches
offset_tiled        = 0,0,0

# Set these to use "chunklist" mode which loads cubes on-the-fly from different parts of the dataset.
chunk_range_beg     = 17,19,2, 17,23,1, 22,23,1, 22,18,1, 22,23,2, 19,22,2

# chunk_range_beg is set and end range is empty, then chunk_range_beg are assumed to be single chunks
#chunk_range_end     = 23,27,7, 28,25,6

# define offsets, if set for "chunk list mode uses ranges and this list is empty, defaults to all zeros
#offset_list        =  0,0,0,   0,0,0,   0,0,0,   0,0,64

# if chunklist or chunkrange mode, the max in chunk_range_beg to use for rand batches
chunk_range_rand    = 6

# if chunklist or chunkrange mode, whether to select in order or randomly for randomized batches
#chunk_list_rand     = False

##############################
# Optional options that get re-ordered on reslice
##############################

# Size of voxels to sample over for random batches
size_rand           = 128,128,128

# Number of zslices to append for tiled batches. Default to Z value of rand_size (after reslice re-ordered)
# Use nz_tiled of zero to not load any tiled batches (for no test slices or chunklist mode)
nz_tiled            = 0

# Frontend "read_size" area for a single set of dense labels. Default to rand_size
read_size           = -1,-1,-1

# Use along with read_size to specify border around read_size cubes not to select rand examples from
read_border         = 0,0,0

##############################
# Optional data pre-processing options
##############################

# Scalar mean value to subtract from image examples (< 0 for mean over all input data, 0 to do nothing)
EM_mean             = 160
#EM_mean             = -1.0
#EM_mean             = 0.0

# Scalar std value to divide out of image examples (< 1 for std over all input data, 1 to do nothing)
#EM_std              = 8.613455507995173
#EM_std              = -1.0
EM_std              = 1.0

# For pre-processing that requires initialization, how many random batches to use for init
preproc_nbatches    = 20
#preproc_nbatches    = 1

# Subtract overall mean and divide variance from all batches, uses init
overall_normalize   = False

# Subtract per-pixel mean and divide variance from all batches, uses init
pixel_normalize     = False

# Subtract per-case mean and divide variance from all batches
case_normalize      = False

# whiten the input data using specified method, uses init
#whiten              = zca
whiten              = none

# regularization parameter to use for whitening
whiten_epsilon      = 0.4

# Load a previously calculated whitening matrix
whiten_load         = 

# Typical preprocessing of images, upsample, apply filter, downsample, apply optional gamma
#em_standard_filter  = 3,3
em_standard_idelta  = 0.5,0.5
em_standard_gamma   = 0.8

